---
title: "task1_baseball_dataset"
author: "Adam"
date: "2024-09-18"
output: html_document
---

Installing libraries and dependencies for this R Markdown notebook

```{r}
if (!require(tidyverse)) install.packages('tidyverse', dependencies=TRUE)
if (!require(corrplot)) install.packages('corrplot', dependencies=TRUE)
if (!require(rmarkdown)) install.packages('rmarkdown', dependencies=TRUE)
if (!require(gridextra)) install.packages('gridExtra', dependencies=TRUE)

if (!require(tidyverse)) install.packages('tidyverse', dependencies=TRUE)
if (!require(rpart)) install.packages('rpart', dependencies=TRUE)
if (!require(rpart.plot)) install.packages('rpart.plot', dependencies=TRUE)
if (!require(caret)) install.packages('caret', dependencies=TRUE)

library(tidyverse)
library(corrplot)
library(rmarkdown)
library(gridExtra)
library(random)

library(tidyverse)
library(rpart)
library(rpart.plot)
library(caret)
```

load the database file

```{r}
library(readr)
data <- read_csv("baseball_dataset.csv")
View(baseball_dataset)
```

------------------------------------------------------------------------

### Step 1: Covariance and Correlation Analysis

```{r}
# Function to compute covariance and correlation
compute_cov_cor <- function(data) {
  data_filtered <- select(data, R, E, HR, RA, SOA) # Selecting relevant columns
  cov_matrix <- cov(data_filtered) # Covariance matrix
  cor_matrix <- cor(data_filtered) # Correlation matrix
  list(cov_matrix = cov_matrix, cor_matrix = cor_matrix)
}

# Call the function to compute covariance and correlation
results <- compute_cov_cor(data)

# Display Covariance Matrix
cat("Covariance Matrix:\n")
print(results$cov_matrix)

# Display Correlation Matrix
cat("\nCorrelation Matrix:\n")
print(results$cor_matrix)

# Visualize the Correlation Matrix
corrplot(results$cor_matrix, method = "color", title = "Correlation Matrix", mar=c(0,0,1,0))
```

### Interpretation:

(click on the icons to flip between the two outputs, covariance and correlation)\
Covariance measures how much two variables change together. If the covariance is positive, they increase together.\
A large positive covariance indicates that the two variables are positively correlated, while a large negative covariance indicates negative correlation.

-   **R (Runs Scored) and HR (Home Runs)**: The covariance between runs scored and home runs is 4449.84, which is positive and relatively large, indicating that more home runs tend to result in more runs scored.
-   **E (Errors) and RA (Opponents Runs Scored)**: The covariance between errors and opponents' runs scored is -89.67, a very small negative value, suggesting no strong relationship between these two.
-   **E (Errors) and SOA (Strikeouts by Pitchers)**: The negative covariance of -23019.08 suggests that more errors are associated with fewer strikeouts by pitchers, which makes sense because poor fielding (more errors) might indicate weaker overall team defense.

Correlation values range between -1 and 1. A value closer to 1 shows a strong positive relationship, whereas a value close to -1 indicates a strong negative relationship.

-   **R (Runs Scored) and HR (Home Runs)**: The correlation is 0.50, showing a moderate positive relationship. As expected, teams that hit more home runs also tend to score more runs.
-   **E (Errors) and HR (Home Runs)**: The correlation is -0.69, which indicates a strong negative relationship. This suggests that teams making more errors tend to hit fewer home runs.
-   **HR (Home Runs) and SOA (Strikeouts by Pitchers)**: A correlation of 0.80 suggests a strong positive relationship. This might indicate that teams with more home runs tend to have pitchers who get more strikeouts, which could be reflective of overall team quality.

------------------------------------------------------------------------

## Step 2: Scatter Plot Analysis

### Scatter Plot for AB (At Bats) vs H (Hits by Batters) and HA (Hits Allowed) vs BBA (Walks Allowed)

```{r}
create_scatter_plots <- function(data) {
  
  # Scatter plot, AB vs H
  p1 <- ggplot(data, aes(x=AB, y=H)) +
    geom_point(color="blue") +
    labs(title="At Bats vs Hits", x="At Bats (AB)", y="Hits (H)") +
    theme_minimal()
  
  # Scatter plot, HA vs BBA
  p2 <- ggplot(data, aes(x=HA, y=BBA)) +
    geom_point(color="green") +
    labs(title="Hits Allowed vs Walks Allowed", x="Hits Allowed (HA)", y="Walks Allowed (BBA)") +
    theme_minimal()
  
  # Arrange plots side by side
  gridExtra::grid.arrange(p1, p2, ncol = 2)
}

create_scatter_plots(data)
```

### Interpretation:

placeholder text

------------------------------------------------------------------------

## Step 3: Histograms for Teams Across Two 10-Year Periods

### Selecting Teams

Here, we randomly select two teams in addition to the Houston Astros and visualize the distribution of `TARGET` (High, Average, Low) for the two periods: 2004-2013 and 2014-2023.

I used a set `randomness seed (31)` in this code so that the analysis section would still line up with the random teams when this code is run multiple times. Changing the randomness seed will change the chosen teams.

```{r}
# Filter the dataset for years after 2004
data_after_2004 <- data %>% filter(yearID >= 2004)

# Randomly select two teams excluding the Houston Astros
teams_list <- unique(data_after_2004$name)
teams_list <- teams_list[teams_list != "Houston Astros"]

set.seed(30)  # seed for reproducibility

random_teams <- sample(teams_list, 2)
random_teams <- c("Houston Astros", random_teams) 

# create histograms
create_histograms <- function(team_name, data) {
  data_2004_2013 <- data %>% filter(name == team_name & yearID >= 2004 & yearID <= 2013)
  data_2014_2023 <- data %>% filter(name == team_name & yearID >= 2014 & yearID <= 2023)

data_2004_2013 <- data_2004_2013 %>%
  mutate(TARGET = factor(TARGET, levels = c("LOW", "AVERAGE", "HIGH")))

data_2014_2023 <- data_2014_2023 %>%
  mutate(TARGET = factor(TARGET, levels = c("LOW", "AVERAGE", "HIGH")))

# Create histograms for TARGET class distribution for both time periods
p1 <- ggplot(data_2004_2013, aes(x=TARGET, fill=TARGET)) +
  geom_bar() +
  labs(title=paste(team_name, "2004-2013"), x="TARGET Class", y="Count") +
  scale_x_discrete(drop=FALSE) +  
  theme_minimal()+
  theme(legend.position = "none")

p2 <- ggplot(data_2014_2023, aes(x=TARGET, fill=TARGET)) +
  geom_bar() +
  labs(title=paste(team_name, "2014-2023"), x="TARGET Class", y="Count") +
  scale_x_discrete(drop=FALSE) + 
  theme_minimal()+
  theme(legend.position = "none")

  # Arrange side by side
  gridExtra::grid.arrange(p1, p2, ncol = 2)
}

# Generate histograms for the three teams
for (team in random_teams) {
  print(paste("Creating histograms for team:", team))
  create_histograms(team, data_after_2004)
}

```

### Interpretation:

1.  Houston Astros (2004-2013 and 2014-2023)

2.  Oakland Athletics (2004-2013 and 2014-2023)

3.  Texas Rangers (2004-2013 and 2014-2023)

------------------------------------------------------------------------

## Step 4: BB & SB Box Plots

```{r}
# Filter out data that has the TARGET column (High/Average/Low)
data_filtered <- data %>% filter(!is.na(TARGET))

# create box plots for a specific attribute and compare across TARGET classes
create_boxplots <- function(data, attribute) {
  
  # Box plot for the attribute grouped by TARGET class (Low, Average, High)
  p1 <- ggplot(data, aes(x=TARGET, y=get(attribute), fill=TARGET)) +
    geom_boxplot() +
    labs(title=paste(attribute, "by TARGET Class"), x="TARGET Class", y=attribute) +
    theme_minimal()
  
  # Box plot for the attribute for all instances in the dataset
  p2 <- ggplot(data, aes(x="All Instances", y=get(attribute))) +
    geom_boxplot(fill="lightblue") +
    labs(title=paste(attribute, "for All Instances"), x="All Instances", y=attribute) +
    theme_minimal()

  # Arrange box plots side by side
  gridExtra::grid.arrange(p1, p2, ncol = 2)
}

# Create box plots for BB (Walks by Batters)
create_boxplots(data_filtered, "BB")

# Create box plots for SB (Stolen Bases)
create_boxplots(data_filtered, "SB")
```

### Interpretation:

BB (Walks by Batters):

------------------------------------------------------------------------

## Step 5: supervised scatter plots

```{r}
# Filter out data that has the TARGET column (High/Average/Low)
data_filtered <- data %>% filter(!is.na(TARGET))

# create scatter plots with TARGET as the class variable
create_supervised_scatterplot <- function(data, x_attr, y_attr) {
  
  # Create scatter plot
  plot <- ggplot(data, aes_string(x=x_attr, y=y_attr, color="TARGET")) +
    geom_point(alpha=0.7, size=3) +
    labs(title=paste("Supervised Scatter Plot:", x_attr, "vs", y_attr),
         x=x_attr, y=y_attr) +
    theme_minimal() +
    scale_color_manual(values = c("LOW" = "red", "AVERAGE" = "yellow", "HIGH" = "green")) +
    theme(legend.position = "bottom")
  
  print(plot)
}

# Scatter plots for the pairs HB/SO, CG/SHO, and IPOuts/DP
create_supervised_scatterplot(data_filtered, "HBP", "SO")
create_supervised_scatterplot(data_filtered, "CG", "SHO")
create_supervised_scatterplot(data_filtered, "IPouts", "DP")
```

### Interpretation:

---placeholder text—

------------------------------------------------------------------------

## Step 6: comparing density plots

```{r}
# Filter out data that has the TARGET column (High/Average/Low)
data_filtered <- data %>% filter(!is.na(TARGET))

# Compute Wins Percentage (W / G) and Errors Per Game (E / G)
data_filtered <- data_filtered %>%
  mutate(WP = W / G, EPG = E / G)

# density plots for Wins Percentage and Errors Per Game
create_density_plots <- function(data) {
  
  # Density plot, Wins Percentage grouped by TARGET
  p1 <- ggplot(data, aes(x=WP, fill=TARGET)) +
    geom_density(alpha=0.5) +
    labs(title="Density Plot: Wins Percentage by TARGET", x="Wins Percentage", y="Density") +
    theme_minimal() +
    scale_fill_manual(values = c("LOW" = "red", "AVERAGE" = "yellow", "HIGH" = "green")) +
    theme(legend.position = "bottom")
  
  # Density plot for Errors Per Game (EPG) grouped by TARGET
  p2 <- ggplot(data, aes(x=EPG, fill=TARGET)) +
    geom_density(alpha=0.5) +
    labs(title="Density Plot: Errors Per Game by TARGET", x="Errors Per Game", y="Density") +
    theme_minimal() +
    scale_fill_manual(values = c("LOW" = "red", "AVERAGE" = "yellow", "HIGH" = "green")) +
    theme(legend.position = "bottom")

  # Arrange side by side
  gridExtra::grid.arrange(p1, p2, ncol = 2)
  
}

create_density_plots(data_filtered)
```

### Interpretation:

placeholder text

------------------------------------------------------------------------

## Step 7: supervised scatter plots

```{r}
# Filter data for teams that won the World Series (WSWin = 'Y')
ws_winners <- data %>% filter(WSWin == "Y")

# Create table that counts number of each TARGET class
team_target_counts <- ws_winners %>%
  group_by(name) %>%
  summarise(
    High_Count = sum(TARGET == "HIGH"),
    Average_Count = sum(TARGET == "AVERAGE"),
    Low_Count = sum(TARGET == "LOW"),
    Total_WS_Wins = n()  # Count of how many times the team won the WS
  )
print(team_target_counts)

# histograms for (W) and (L) for each team
create_histograms_for_team <- function(team_name, data) {
  # Filter data for selected team
  team_data <- data %>% filter(name == team_name)

  # histogram for (W)
  p1 <- ggplot(team_data, aes(x=W)) +
    geom_histogram(binwidth = 2, fill="blue", color="black") +
    labs(title=paste(team_name, "- Wins"), x="Wins", y="Count") +
    theme_minimal()

  # histogram for (L)
  p2 <- ggplot(team_data, aes(x=L)) +
    geom_histogram(binwidth = 2, fill="red", color="black") +
    labs(title=paste(team_name, "- Losses"), x="Losses", y="Count") +
    theme_minimal()

  # Arrange histograms side by side
  gridExtra::grid.arrange(p1, p2, ncol = 2)
}

# Loop, every team that won WorldSeries, create histograms for W/L
teams <- unique(ws_winners$name)
for (team in teams) {
  print(paste("Creating histograms for team:", team))
  create_histograms_for_team(team, ws_winners)
}
```

### Interpretation:

placeholder text

------------------------------------------------------------------------

## Step 8: z-score table

```{r}
# Filter out rows where the WP column  or any of the relevant attributes are NA
data_filtered <- data %>%
  filter(!is.na(WP), !is.na(H), !is.na(SO), !is.na(SOA), !is.na(SHO), !is.na(FP))
```

For step 8, we will do the following steps:

Transform [H, SO, SOA, SHO, FP] into z-scores.

Fit a linear regression model to predict [Win Percentage] using the z-scored attributes.

Find the R² value and coefficients of the model.

```{r}
# Step 1: Transform the specified attributes into z-scores

data_z_processed <- data_filtered %>%
  mutate(
    H_z = scale(H),
    SO_z = scale(SO),
    SOA_z = scale(SOA),
    SHO_z = scale(SHO),
    FP_z = scale(FP)
  )
```

```{r}
# Step 2: Fit a linear model to predict WP using the z-scored attributes

model <- lm(WP ~ H_z + SO_z + SOA_z + SHO_z + FP_z, data = data_z_processed)

# Step 3: Report the R² value and the coefficients of the linear model
r_squared <- summary(model)$r.squared
coefficients <- summary(model)$coefficients
```

```{r}
# Print the R^2 value

cat("R² of the linear model:", r_squared, "\n\n")

# Print the coefficients of the model
cat("Coefficients of the linear model:\n")
print(coefficients)
```

### Interpretation:

placeholder text

------------------------------------------------------------------------

## Step 9: Three decision tree models

```{r}
# Filter the dataset for the relevant attributes (R to FP) and the TARGET column
data_filtered <- data %>%
  filter(!is.na(TARGET)) %>%
  select(R:FP, TARGET)

# Split the dataset into training and testing sets (80% training, 20% testing)
set.seed(42)  # For reproducibility
trainIndex <- createDataPartition(data_filtered$TARGET, p = 0.8, list = FALSE)
train_data <- data_filtered[trainIndex, ]
test_data <- data_filtered[-trainIndex, ]
```

Step 1: Build the first decision tree model with a max depth of 25 nodes

```{r}
model1 <- rpart(TARGET ~ ., data = train_data, method = "class", control = rpart.control(maxdepth = 5, cp = 0.01, maxcompete = 25))

# Visualize the first decision tree
rpart.plot(model1, main = "Decision Tree Model 1")
```

Step 2: Build the second decision tree model (try a different max depth or complexity parameter)

```{r}
model2 <- rpart(TARGET ~ ., data = train_data, method = "class", control = rpart.control(maxdepth = 4, cp = 0.02, maxcompete = 25))

# Visualize the second decision tree
rpart.plot(model2, main = "Decision Tree Model 2")
```

Step 3: Build the third decision tree model (with a different set of hyperparameters)

```{r}
model3 <- rpart(TARGET ~ ., data = train_data, method = "class", control = rpart.control(maxdepth = 3, cp = 0.015, maxcompete = 25))

# Visualize the third decision tree
rpart.plot(model3, main = "Decision Tree Model 3")
```

Step 4: Evaluate the accuracy of each model on both training and testing sets

```{r}
# calculate accuracy
calculate_accuracy <- function(model, train_data, test_data) {
  train_pred <- predict(model, newdata = train_data, type = "class")
  test_pred <- predict(model, newdata = test_data, type = "class")
  
  train_accuracy <- mean(train_pred == train_data$TARGET)
  test_accuracy <- mean(test_pred == test_data$TARGET)
  
  return(list(train_accuracy = train_accuracy, test_accuracy = test_accuracy))
}

# Calculate and print accuracies for each model
accuracy_model1 <- calculate_accuracy(model1, train_data, test_data)
cat("Model 1 - Training Accuracy:", accuracy_model1$train_accuracy, "\n")
cat("Model 1 - Testing Accuracy:", accuracy_model1$test_accuracy, "\n\n")

accuracy_model2 <- calculate_accuracy(model2, train_data, test_data)
cat("Model 2 - Training Accuracy:", accuracy_model2$train_accuracy, "\n")
cat("Model 2 - Testing Accuracy:", accuracy_model2$test_accuracy, "\n\n")

accuracy_model3 <- calculate_accuracy(model3, train_data, test_data)
cat("Model 3 - Training Accuracy:", accuracy_model3$train_accuracy, "\n")
cat("Model 3 - Testing Accuracy:", accuracy_model3$test_accuracy, "\n\n")
```

### Interpretation:

placeholder text

------------------------------------------------------------------------

## Step 10: Conclusion

placeholder text, put conclusion here. At most 13 sentences.
